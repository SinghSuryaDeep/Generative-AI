{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f3f39ccf-695f-4470-8d12-8b01fec360f1",
   "metadata": {},
   "source": [
    "# Retrieval Augmented Generation (RAG) & Few-Shot Prompting Medical Chat Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1f2ef5-f360-4c88-9ea9-246460209ca6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain.embeddings import HuggingFaceEmbeddings\n",
    "from langchain.vectorstores import FAISS\n",
    "from langchain.chains import ConversationalRetrievalChain\n",
    "from langchain.text_splitter import CharacterTextSplitter\n",
    "from langchain_community.document_loaders import TextLoader\n",
    "from langchain_community.vectorstores import FAISS\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from langchain.document_loaders import PyPDFLoader\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from ibm_watson_machine_learning.metanames import GenTextParamsMetaNames as GenParams\n",
    "from ibm_watson_machine_learning.foundation_models.utils.enums import ModelTypes, DecodingMethods\n",
    "from ibm_watson_machine_learning.foundation_models import Model\n",
    "from ibm_watson_machine_learning.foundation_models.extensions.langchain import WatsonxLLM\n",
    "from datetime import date\n",
    "import uvicorn\n",
    "from fastapi import FastAPI, HTTPException\n",
    "app = FastAPI(version=\"3.0.2\")\n",
    "class MedicalAssistant:\n",
    "    def __init__(self):\n",
    "        self.project_id = \"Your project id\"\n",
    "        self.model_id = \"mistralai/Mixtral-8x7B-v0.1\"\n",
    "        self.api_key =  \"Your api key\"\n",
    "        self.url = \"Your url\"\n",
    "    def get_credentials(self):\n",
    "    \treturn {\n",
    "    \t\t\"url\" : self.url,\n",
    "    \t\t\"apikey\" :  self.api_key\n",
    "    \t}\n",
    "    def ReferPolicy(self,query):\n",
    "        loader = PyPDFLoader(\"Healthcare Policy Document.pdf\")\n",
    "        data = loader.load()\n",
    "        chunk_size = 1000\n",
    "        chunk_overlap= 10\n",
    "        text_splitter = RecursiveCharacterTextSplitter(chunk_size=chunk_size, chunk_overlap=chunk_overlap)\n",
    "        docs = text_splitter.split_documents(data)\n",
    "        model_name = \"sentence-transformers/all-mpnet-base-v2\"\n",
    "        model_kwargs = {\"device\": \"cpu\"}\n",
    "        embeddings = HuggingFaceEmbeddings(model_name=model_name, model_kwargs=model_kwargs)\n",
    "        vectorstore = FAISS.from_documents(docs, embeddings)\n",
    "        params = {\n",
    "                    GenParams.MAX_NEW_TOKENS: 500,\n",
    "                    GenParams.MIN_NEW_TOKENS: 1,\n",
    "                    GenParams.DECODING_METHOD: DecodingMethods.GREEDY\n",
    "                }\n",
    "        credentials = {\n",
    "            'url': self.url,\n",
    "            'apikey' : self.api_key\n",
    "        }\n",
    "        llm = Model(\n",
    "            model_id= self.model_id,\n",
    "            credentials=credentials,\n",
    "            params=params,\n",
    "            project_id=self.project_id)\n",
    "        llm = WatsonxLLM(model=llm)\n",
    "        chain = ConversationalRetrievalChain.from_llm(llm, vectorstore.as_retriever(), return_source_documents=True)\n",
    "        chat_history = []\n",
    "        result = chain({\"question\": query, \"chat_history\": chat_history})\n",
    "        ans = str(result['answer']).replace('4','ti')\n",
    "        return ans\n",
    "    def NotPolicy(self,query):\n",
    "        today = date.today()\n",
    "        today_date = today.strftime(\"%Y-%m-%d\")\n",
    "        def get_credentials():\n",
    "        \treturn {\n",
    "        \t\t\"url\" : self.url,\n",
    "        \t\t\"apikey\" : self.api_key\n",
    "        \t}\n",
    "        parameters = {\n",
    "            \"decoding_method\": \"greedy\",\n",
    "            \"max_new_tokens\": 200,\n",
    "            \"repetition_penalty\": 1.1,\n",
    "            \"temperature\":0.1\n",
    "        }\n",
    "        \n",
    "        model = Model(\n",
    "        \tmodel_id =  self.model_id,\n",
    "        \tparams = parameters,\n",
    "        \tcredentials = get_credentials(),\n",
    "        \tproject_id = self.project_id\n",
    "        \t)\n",
    "        \n",
    "        prompt_input = f'''\n",
    "        You are a medical assistant. Your task is to respond to the query asked by the patient, providing concise answers. \n",
    "        If patient asks for appointment book it after 2 days from {today_date}.\n",
    "        If you don't understand the question, instruct the patient to call the help line at phone number: 9999999999.\n",
    "        \n",
    "        Query: {query}\n",
    "        Anser: \n",
    "        '''\n",
    "        respnse = model.generate_text(prompt=prompt_input)\n",
    "        return str(respnse)\n",
    "\n",
    "    def MedicalAssitantOrchestator(self,query):\n",
    "        parameters = {\n",
    "            \"decoding_method\": \"greedy\",\n",
    "            \"max_new_tokens\": 200,\n",
    "            \"repetition_penalty\": 1.1,\n",
    "            \"temperature\":0.1\n",
    "        }\n",
    "        model = Model(\n",
    "        \tmodel_id =  self.model_id,\n",
    "        \tparams = parameters,\n",
    "        \tcredentials = self.get_credentials(),\n",
    "        \tproject_id = self.project_id\n",
    "        \t)\n",
    "        prompt_input = f'''\n",
    "        You are an medical query orchestrator. You need to understand patient query and answer accurately in 2 answers only \"Refer Policy\" or \"Not a Policy\". Answer the Latest_Query'\n",
    "    \n",
    "        Query: what are the documents required for the claim?\n",
    "        Answer: 'Refer Policy'\n",
    "    \n",
    "        Query: what is the claim process?\n",
    "        Answer: 'Refer Policy'\n",
    "    \n",
    "        Query: what are the documents required for the claim?\n",
    "        Answer: 'Refer Policy'\n",
    "    \n",
    "        Query: Book my appointment for tomorrow?\n",
    "        Answer: 'Not a Policy'\n",
    "    \n",
    "        Query: what is the Healthcare Policy Document?\n",
    "        Answer: 'Refer Policy'\n",
    "    \n",
    "        Query: what is the helpline number?\n",
    "        Answer: 'Not a Policy'\n",
    "    \n",
    "        Query: what is the insurance Policy?\n",
    "        Answer: 'Refer Policy'\n",
    "    \n",
    "        Latest_Query: {query}\n",
    "        Answer:\n",
    "        '''\n",
    "        respnse = model.generate_text(prompt=prompt_input)\n",
    "        if 'Refer Policy' in respnse:\n",
    "            respnse = self.ReferPolicy(query)\n",
    "            return respnse\n",
    "        respnse =  self.NotPolicy(query)\n",
    "        return str(respnse).strip()\n",
    "    \n",
    "def MedicalAssistantQA(query):\n",
    "    orchestrator = MedicalAssistant()\n",
    "    response = orchestrator.MedicalAssitantOrchestator(query)\n",
    "    print('Response: ',response.strip())\n",
    "    return response\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "523a5621-fb26-4caf-9e61-e853e7cfab78",
   "metadata": {},
   "source": [
    "# Question and Answer Medical Assistant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "4cd61f9a-8d2a-4307-a489-bccd59e521b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  What are the documents required for the insurance claim?\n",
      "Response:  The documents required for the insurance claim include medical records documenting the need for the plastic surgery procedure, a physician's recommendation or referral for the surgery, any pre-authorization forms obtained prior to the surgery, and an itemized billing statement from the healthcare provider.\n"
     ]
    }
   ],
   "source": [
    "query = \"What are the documents required for the insurance claim?\"\n",
    "print(\"Query: \",query)\n",
    "ans = MedicalAssistantQA(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b68598bf-476c-4931-b50d-d1cf171629cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  Does plastic surgery covered in my insurance?\n",
      "Response:  Based on the healthcare policy document provided, Plastic surgery procedures are only covered by insurance if they are deemed medically necessary. Prior authorization from the insurance provider is required before undergoing any plastic surgery procedure. If you are considering Plastic surgery for cosmetic purposes, it is likely not covered by insurance and would require full payment by the patient. To determine if your specific Plastic surgery procedure is covered, you should contact your insurance provider and provide them with the detailed medical necessity and any supporting documentation. They will be able to confirm the coverage and provide you with the necessary steps to follow for reimbursement.\n"
     ]
    }
   ],
   "source": [
    "query = \"Does plastic surgery covered in my insurance?\"\n",
    "print(\"Query: \",query)\n",
    "ans = MedicalAssistantQA(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d4af084-6a2f-4a9d-820f-cef7d541ad64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  I have claimed Rs.2,00,000 insurance coverage how much total coverage do I have left?\n",
      "Response:  Based on the information provided, you have claimed Rs. 2,00,000 out of a total coverage limit of Rs. 5,00,000 for medically necessary plastic surgery procedures. Therefore, you have Rs. 3,00,000 in insurance coverage left.\n"
     ]
    }
   ],
   "source": [
    "query = \"I have claimed Rs.2,00,000 insurance coverage how much total coverage do I have left?\"\n",
    "print(\"Query: \",query)\n",
    "ans = MedicalAssistantQA(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e2f1a298-307f-4cf9-9056-5952990f4524",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  Please book an appointment with a Dermatologist?\n",
      "Response:  Sure, I can help you with that. I have booked an appointment for you with a Dermatologist on February 27th, 2024.\n"
     ]
    }
   ],
   "source": [
    "query = \"Please book an appointment with a Dermatologist?\"\n",
    "print(\"Query: \",query)\n",
    "ans = MedicalAssistantQA(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "e053befb-31f0-49c0-a3bc-0e084c55ea74",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Query:  What is your Help line number?\n",
      "Response:  9999999999\n"
     ]
    }
   ],
   "source": [
    "query = \"What is your Help line number?\"\n",
    "print(\"Query: \",query)\n",
    "ans = MedicalAssistantQA(query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57d0080-e875-4e40-b259-ce9827a3b4ad",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
